{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96663d4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Matched\n",
      "---------------------------------------------------------------\n",
      "Emblem Matched\n",
      "---------------------------------------------------------------\n",
      "GOI Detected and validated.....\n",
      "---------------------------------------------------------------\n",
      "Adhar number is correct\n",
      "---------------------------------------------------------------\n",
      "Name is correct.....\n",
      "----------------------------\n",
      "Date of birth is correct.....\n",
      "----------------------------\n",
      "Gender is correct.....\n",
      "----------------------------\n",
      "Adhar number is correct.....\n",
      "----------------------------\n",
      "Father Name is correct.....\n",
      "----------------------------\n",
      "Pincode is correct.....\n",
      "----------------------------\n",
      "Address is correct.....\n",
      "----------------------------\n",
      "---------------------------------------------------------------\n",
      "\u001b[38;2;0;255;0mFRONT APPROVED  \u001b[38;2;255;255;255m\n",
      "---------------------\n",
      "\u001b[38;2;0;255;0mBACK APPROVED \u001b[38;2;255;255;255m\n",
      "---------------------\n",
      "---------------------\n",
      "\u001b[38;2;0;255;0mProvided details are matching with Adhar \u001b[38;2;255;255;255m\n",
      "\u001b[38;2;0;255;0mOVERALL APPROVED \u001b[38;2;255;255;255m\n",
      "---------------------\n",
      "---------------------\n",
      "\u001b[38;2;255;0;0m282001 \u001b[38;2;255;255;255m\n",
      "None\n",
      "\u001b[38;2;255;0;0m282001 \u001b[38;2;255;255;255m\n",
      "None\n",
      "\u001b[38;2;0;255;0mUIDAI Matched------------------------------ \u001b[38;2;255;255;255m\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'KYC Successful'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface import utils\n",
    "from keras_vggface import VGGFace\n",
    "from PIL import Image, ImageEnhance\n",
    "from keras.engine.training import  Model\n",
    "from scipy.spatial.distance import cosine\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.layers import Flatten, Dense, Input,concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def initial():\n",
    "    count_front = 0\n",
    "    global count\n",
    "    count = 0\n",
    "    global fail_counter\n",
    "    fail_counter = 0\n",
    "    # data_check variable will check the data validity\n",
    "    global data_check \n",
    "    data_check = {}\n",
    "    # final_data variable will have the data details as per approved or not approved\n",
    "    global final_data \n",
    "    final_data = {}\n",
    "    global simlarity_score\n",
    "    simlarity_score = {}\n",
    "\n",
    "#------------------------- Face Similarity Starts Here -------------------------------------\n",
    "\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "    img = plt.imread(filename)\n",
    "    detector = MTCNN()\n",
    "    results = detector.detect_faces(img)\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    enhancer = ImageEnhance.Sharpness(image)\n",
    "    image = enhancer.enhance(0.5)\n",
    "    face_array = np.asarray(image)\n",
    "    return face_array\n",
    "\n",
    "def get_embeddings(filenames):\n",
    "    faces = [extract_face(f) for f in filenames]\n",
    "    samples = np.asarray(faces, 'float32')\n",
    "    samples = utils.preprocess_input(samples, version=2)\n",
    "    model = VGGFace(model='senet50', include_top=False, input_shape=(224, 224, 3), pooling='max')\n",
    "    pred = model.predict(samples)\n",
    "    return pred\n",
    "\n",
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "    global count\n",
    "    global simlarity_score\n",
    "    score = cosine(known_embedding, candidate_embedding)\n",
    "    simlarity_score[\"Face_Similarity_Score\"] = ((1-score) * 100)\n",
    "\n",
    "    if (1-score) > 0.5:\n",
    "        notes = \"Face Matched\"\n",
    "        data_check[\"Face_Validation\"] = \"Validated\"\n",
    "        final_data[\"Face_Validation_status\"] = \"OK\"\n",
    "        count = count + 1\n",
    "    else:\n",
    "        notes = \"Face Not Matched\"\n",
    "        data_check[\"Face_Validation\"] = \"Not Validated\"\n",
    "        final_data[\"Face_Validation_status\"] = \"Not OK\"\n",
    "    return  notes\n",
    "\n",
    "def face_similarity_executor(adhaar_front_path, user_image_path):\n",
    "\n",
    "    embeddings = get_embeddings([adhaar_front_path, user_image_path])\n",
    "    return print(is_match(embeddings[0], embeddings[1]))\n",
    "\n",
    "#------------------------- Face Similarity Ends Here ----------------------------------------\n",
    "\n",
    "\n",
    "#------------------------- Emblem Detection Starts Here -------------------------------------\n",
    "\n",
    "def Emblem_Extractor(img, template):\n",
    "    height, width = img.shape[:2]\n",
    "    image_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    w, h = template.shape[::-1]\n",
    "    result = cv2.matchTemplate(image_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(img, top_left, bottom_right, (0,0,255), 1)\n",
    "    cv2.imwrite(r'adhaar_emblem.jpg', img)\n",
    "\n",
    "    x = top_left[0]\n",
    "    y = top_left[1]\n",
    "    w = bottom_right[0] - top_left[0]\n",
    "    h = bottom_right[1] - top_left[1]\n",
    "\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    return crop_img \n",
    "\n",
    "def Emblem_Validator(img, template):\n",
    "\n",
    "    global count\n",
    "    global simlarity_score\n",
    "\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=True, pooling='max', input_shape=(224, 224, 3))\n",
    "    basemodel = Model(inputs=vgg16.input, outputs=vgg16.get_layer('fc2').output)\n",
    "\n",
    "    def get_feature_vector(img):\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        feature_vector = basemodel.predict(img.reshape(1, 224, 224, 3))\n",
    "        return feature_vector\n",
    "\n",
    "    def calculate_similarity(vector1, vector2):\n",
    "        return (1 - cosine(vector1, vector2))\n",
    "\n",
    "    f1 = get_feature_vector(img)\n",
    "    f2 = get_feature_vector(template)\n",
    "    calculate_similarity(f1, f2)\n",
    "\n",
    "    simlarity_score[\"Emblem_Validation_Score\"] = (calculate_similarity(f1, f2) * 100)\n",
    "\n",
    "    if calculate_similarity(f1, f2) >= 0.5:\n",
    "        count = count + 1\n",
    "        data_check[\"Emblem_Validation\"] = \"Validated\"\n",
    "        final_data[\"Emblem_Validation\"] = \"OK\"\n",
    "        return print(\"Emblem Matched\")\n",
    "    else:\n",
    "        data_check[\"Emblem_Validation\"] = \"Not Validated\"\n",
    "        final_data[\"Emblem_Validation\"] = \"Not OK\"\n",
    "        return print(\"Emblem Failed to Match\")\n",
    "\n",
    "def emblem_validation_executor(path_to_image, path_to_template):\n",
    "\n",
    "    template_1 = cv2.imread(path_to_template, 0)\n",
    "    input_image = cv2.imread(path_to_image)\n",
    "\n",
    "    input_image = Emblem_Extractor(input_image, template_1)\n",
    "    template_2 = cv2.imread(path_to_template)\n",
    "    return Emblem_Validator(input_image, template_2)\n",
    "\n",
    "#------------------------- Emblem Detection Ends Here -----------------------------------\n",
    "\n",
    "#------------------------- GOI Detection Start Here -------------------------------------\n",
    "\n",
    "def goi_detection(front_image_path, path_to_emblem_template, path_to_goi_template):\n",
    "\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "    image_color = cv2.imread(front_image_path)\n",
    "    height, width = image_color.shape[:2]\n",
    "    image_gray = cv2.cvtColor(image_color, cv2.COLOR_BGR2GRAY)\n",
    "    template = cv2.imread(path_to_emblem_template, 0)  # ------------------- Template Need to be loaded\n",
    "    w_1, h_1 = template.shape[::-1]\n",
    "\n",
    "    # Load template\n",
    "    template_1 =  cv2.imread(path_to_goi_template)  # --------------------- Template Need to be loaded\n",
    "    w_2, h_2 = template_1.shape[1],template_1.shape[0]\n",
    "\n",
    "    # Perform template matching!\n",
    "    result = cv2.matchTemplate(image_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Find the indices of the object to be find \n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    # Draw a box around the object (if found)\n",
    "    top_left = (max_loc[0]+w_1,max_loc[1])\n",
    "    bottom_right = (top_left[0] + w_2+100+50+10+10, top_left[1] + h_2+20)\n",
    "    cv2.rectangle(image_color, top_left, bottom_right, (0,0,255), 1)\n",
    "\n",
    "    cv2.imwrite('mine_goi.jpg', image_color)  # ----------------------- Define Working Directory to store\n",
    "\n",
    "    # Cropping and saving\n",
    "    x = top_left[0]\n",
    "    y = top_left[1]\n",
    "    w = bottom_right[0] - top_left[0]\n",
    "    h = bottom_right[1] - top_left[1]\n",
    "\n",
    "    crop_img = image_color[y:y+h, x:x+w]\n",
    "    cv2.imwrite('crop_goi_adhar.jpg', crop_img) # ----------------------- Define Working Directory to store\n",
    "\n",
    "    # Extraction of text GOI(if found)\n",
    "\n",
    "    # Read image from which text needs to be extracted\n",
    "    img = cv2.imread(\"crop_goi_adhar.jpg\") # ---------------------------- Load the previously saved Image \n",
    "\n",
    "    # Preprocessing the image starts\n",
    "\n",
    "    # Convert the image to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Performing OTSU threshold\n",
    "    ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Specify structure shape and kernel size. \n",
    "\n",
    "    # Empty ocr_text\n",
    "    ocr_text_front = ' ' \n",
    "    text_1 = ' '\n",
    "    text_2 = ' '\n",
    "    text_3 = ' '\n",
    "    for i in range(1,10):\n",
    "\n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (i,i))\n",
    "        # dilation = rect_kernel  \n",
    "        # Appplying dilation on the threshold image\n",
    "        dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n",
    "\n",
    "        # Finding contours\n",
    "        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, \n",
    "                                                         cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        # Creating a copy of image\n",
    "        im2 = img.copy()\n",
    "\n",
    "\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            # Drawing a rectangle on copied image\n",
    "            rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Cropping the text block for giving input to OCR\n",
    "            cropped = im2[y:y + h, x:x + w]\n",
    "        #     cv2.imshow('Cropped',cropped)\n",
    "\n",
    "            # Open the file in append mode\n",
    "            file = open(\"recognized.txt\", \"a\")\n",
    "\n",
    "            # Apply OCR on the cropped image\n",
    "            text_1 = pytesseract.image_to_string(cropped,lang='eng',  config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789')\n",
    "            text_2 = pytesseract.image_to_string(cropped)\n",
    "            text_3 = pytesseract.image_to_string(cropped,lang='eng',config=f'-l eng --psm 6 --oem 3 ')\n",
    "\n",
    "            # Text generation  \n",
    "            ocr_text_front = text_1 + text_2 + text_3+ ocr_text_front\n",
    "\n",
    "\n",
    "        if \"GOVERNMENT\" in ocr_text_front.upper() and \"INDIA\" in ocr_text_front.upper():\n",
    "            break\n",
    "\n",
    "\n",
    "            #Address Check\n",
    "    goi_list = [\"GOVERNMENT\",\"INDIA\"]\n",
    "    count_goi = 0\n",
    "    for item in goi_list:\n",
    "        if item.upper() in ocr_text_front.upper():\n",
    "            count_goi = count_goi +1\n",
    "\n",
    "\n",
    "    percent_correct_goi = count_goi/len(goi_list)\n",
    "    simlarity_score[\"GOI\"] = percent_correct_goi\n",
    "\n",
    "    global count\n",
    "\n",
    "    if percent_correct_goi == 1:\n",
    "        count = count + 1\n",
    "        data_check[\"GOI_Validation\"] = \"Validated\"\n",
    "        final_data[\"GOI_Validation_status\"] = \"OK\"\n",
    "        return print(\"GOI Detected and validated.....\")\n",
    "    else:\n",
    "        data_check[\"GOI_Validation\"] = \"Not Validated\"\n",
    "        final_data[\"GOI_Validation_status\"] = \"Not OK\"\n",
    "        return print(\"GOI NOT Detected and validated.....\")\n",
    "\n",
    "#------------------------- GOI Detection Ends Here ----------------------------------\n",
    "\n",
    "#-------------------------Verhoff Algorithm Starts Here -----------------------------\n",
    "\n",
    "def verhoff_algo(UID):\n",
    "    verhoeff_table_d = (\n",
    "        (0,1,2,3,4,5,6,7,8,9),\n",
    "        (1,2,3,4,0,6,7,8,9,5),\n",
    "        (2,3,4,0,1,7,8,9,5,6),\n",
    "        (3,4,0,1,2,8,9,5,6,7),\n",
    "        (4,0,1,2,3,9,5,6,7,8),\n",
    "        (5,9,8,7,6,0,4,3,2,1),\n",
    "        (6,5,9,8,7,1,0,4,3,2),\n",
    "        (7,6,5,9,8,2,1,0,4,3),\n",
    "        (8,7,6,5,9,3,2,1,0,4),\n",
    "        (9,8,7,6,5,4,3,2,1,0))\n",
    "    verhoeff_table_p = (\n",
    "        (0,1,2,3,4,5,6,7,8,9),\n",
    "        (1,5,7,6,2,8,3,0,9,4),\n",
    "        (5,8,0,3,7,9,6,1,4,2),\n",
    "        (8,9,1,6,0,4,3,5,2,7),\n",
    "        (9,4,5,3,1,2,6,8,7,0),\n",
    "        (4,2,8,6,5,7,3,9,0,1),\n",
    "        (2,7,9,3,8,0,6,4,1,5),\n",
    "        (7,0,4,6,9,1,3,2,5,8))\n",
    "\n",
    "    verhoeff_table_inv = (0,4,3,2,1,5,6,7,8,9)\n",
    "\n",
    "    def calcsum(number):\n",
    "        \"\"\"For a given number returns a Verhoeff checksum digit\"\"\"\n",
    "        c = 0\n",
    "        for i, item in enumerate(reversed(str(number))):\n",
    "            c = verhoeff_table_d[c][verhoeff_table_p[(i+1)%8][int(item)]]\n",
    "        return verhoeff_table_inv[c]\n",
    "\n",
    "    def checksum(number):\n",
    "        \"\"\"For a given number generates a Verhoeff digit and\n",
    "        returns number + digit\"\"\"\n",
    "        c = 0\n",
    "        for i, item in enumerate(reversed(str(number))):\n",
    "            c = verhoeff_table_d[c][verhoeff_table_p[i % 8][int(item)]]\n",
    "        return c\n",
    "\n",
    "    def generateVerhoeff(number):\n",
    "        \"\"\"For a given number returns number + Verhoeff checksum digit\"\"\"\n",
    "        return \"%s%s\" % (number, calcsum(number))\n",
    "\n",
    "    def validateVerhoeff(number):\n",
    "        \"\"\"Validate Verhoeff checksummed number (checksum is last digit)\"\"\"\n",
    "        return checksum(number) == 0\n",
    "    global count\n",
    "    first,second,third =  map(int, UID.split(' '))\n",
    "    adhar_number = str(first)+str(second)+str(third)\n",
    "    if validateVerhoeff(adhar_number):\n",
    "        count = count+1\n",
    "        return print(\"Adhar number is correct\")\n",
    "\n",
    "    else:\n",
    "        return print(\"Adhar number is incorrect\")\n",
    "\n",
    "#-------------------------Verhoff Algorithm Ends Here -----------------------------\n",
    "\n",
    "#-------------------------OCR Front & Back Text Extraction Starts Here -----------------------------\n",
    "\n",
    "\n",
    "def adhar_front_text_extraction(front_image_path):\n",
    "\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\" # ------- Location of OCR\n",
    "    img = cv2.imread(front_image_path)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100,100))\n",
    "    dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, \n",
    "                                                     cv2.CHAIN_APPROX_NONE)\n",
    "    im2 = img.copy()\n",
    "\n",
    "    ocr_text_front = ' ' \n",
    "    text_1 = ' '\n",
    "    text_2 = ' '\n",
    "    text_3 = ' '\n",
    "\n",
    "    for cnt in contours:\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cropped = im2[y:y + h, x:x + w]\n",
    "\n",
    "        text_1 = pytesseract.image_to_string(cropped, config=f'-l eng --psm 6 --oem 3 ')\n",
    "        text_2 = pytesseract.image_to_string(cropped)\n",
    "        text_3 = pytesseract.image_to_string(cropped,lang='eng',  config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789')\n",
    "\n",
    "        ocr_text_front = text_1 + text_2 + text_3 + ocr_text_front\n",
    "    return ocr_text_front\n",
    "\n",
    "def adhar_back_text_extraction(back_image_path):\n",
    "\n",
    "    img = cv2.imread(back_image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100,100))\n",
    "    dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n",
    "    contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, \n",
    "                                                     cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    im2 = img.copy()\n",
    "\n",
    "    ocr_text_back = ' ' \n",
    "    text_1 = ' '\n",
    "    text_2 = ' '\n",
    "    text_3 = ' '\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        cropped = im2[y:y + h, x:x + w]\n",
    "\n",
    "        text_1 = pytesseract.image_to_string(cropped, config=f'-l eng --psm 6 --oem 3 ')\n",
    "        text_2 = pytesseract.image_to_string(cropped)\n",
    "        text_3 = pytesseract.image_to_string(cropped,lang='eng',  config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789')\n",
    "\n",
    "        ocr_text_back = text_1  + text_2 + text_3 + ocr_text_back\n",
    "    return ocr_text_back\n",
    "\n",
    "#------------------------- OCR Front & Back Text Extraction Ends Here -----------------------------\n",
    "#------------------------- Extracted Text Validation Starts Here -----------------------------\n",
    "\n",
    "\n",
    "def card_validation(ocr_text_front,ocr_text_back,name,date_of_birth,Gender,UID,father_name,pincode,address):\n",
    "\n",
    "    #FRONT CARD VALIDATION    \n",
    "    count_front = 0\n",
    "\n",
    "    # data_check variable will check the data validity\n",
    "    global data_check \n",
    "    # final_data variable will have the data details as per approved or not approved\n",
    "    global final_data \n",
    "    global simlarity_score\n",
    "    #Name check\n",
    "    name_list = list(name.split(' '))\n",
    "    count_name = 0\n",
    "    for item in name_list:\n",
    "        if item.upper() in ocr_text_front.upper():\n",
    "            count_name = count_name +1\n",
    "\n",
    "    percent_correct_name = count_name/len(name_list)\n",
    "    simlarity_score[\"name\"] = percent_correct_name\n",
    "    if percent_correct_name ==1:\n",
    "        print(\"Name is correct.....\")\n",
    "        print(\"----------------------------\")\n",
    "        count_front = count_front+1\n",
    "        data_check[\"name\"] = \"Validated\"\n",
    "        final_data[\"name\"] = name\n",
    "\n",
    "    else:\n",
    "        print(\"Name is incorrect.....\")\n",
    "        print(\"----------------------------\")\n",
    "        data_check[\"name\"] = \"Not Validated\"\n",
    "        final_data[\"name\"] = \"NA\"\n",
    "    # Date of birth check\n",
    "\n",
    "    if date_of_birth in ocr_text_front:\n",
    "        print(\"Date of birth is correct.....\")\n",
    "        print(\"----------------------------\")\n",
    "        count_front = count_front +1\n",
    "        data_check[\"date_of_birth\"] = \"Validated\"\n",
    "        final_data[\"date_of_birth\"] = date_of_birth\n",
    "        simlarity_score[\"date_of_birth\"] = 1\n",
    "    else:\n",
    "        print(\"Data of birth is incorrect.....\")\n",
    "        print(\"----------------------------\")\n",
    "        data_check[\"date_of_birth\"] = \"Not Validated\"\n",
    "        final_data[\"date_of_birth\"] = \"NA\"\n",
    "        simlarity_score[\"date_of_birth\"] = 0\n",
    "\n",
    "    # Gender check\n",
    "    if Gender.upper() in ocr_text_front.upper():\n",
    "        print(\"Gender is correct.....\")\n",
    "        print(\"----------------------------\")\n",
    "        count_front = count_front +1\n",
    "        data_check[\"Gender\"] = \"Validated\"\n",
    "        final_data[\"Gender\"] = Gender\n",
    "        simlarity_score[\"Gender\"] = 1\n",
    "    else:\n",
    "        print(\"Gender is incorrect.....\")\n",
    "        print(\"----------------------------\")\n",
    "        data_check[\"Gender\"] = \"Not Validated\"\n",
    "        final_data[\"Gender\"] = \"NA\"\n",
    "        simlarity_score[\"Gender\"] = 0\n",
    "\n",
    "    # Adhar card number check\n",
    "    first,second,third =  map(int, UID.split(' '))\n",
    "\n",
    "    uid_list = list(UID.split(' '))\n",
    "    count_uid = 0\n",
    "    for item in uid_list:\n",
    "        if item.upper() in ocr_text_front.upper():\n",
    "            count_uid = count_uid +1\n",
    "\n",
    "    percent_correct_uid = count_uid/len(uid_list)\n",
    "    simlarity_score[\"UID\"] = percent_correct_uid\n",
    "    if percent_correct_uid==1:\n",
    "        print(\"Adhar number is correct.....\")\n",
    "        print(\"----------------------------\")\n",
    "        count_front = count_front +1\n",
    "        data_check[\"UID\"] = \"Validated\"\n",
    "        final_data[\"UID\"] = UID\n",
    "    else:\n",
    "        print(\"Adhar number is incorrect.....\")\n",
    "        print(\"----------------------------\")\n",
    "        data_check[\"UID\"] = \"Not Validated\"\n",
    "        final_data[\"UID\"] = \"NA\"\n",
    "\n",
    "\n",
    "    # BACK CARD VALIDATION    \n",
    "    count_back =0\n",
    "\n",
    "    # Initialising NO for all check\n",
    "\n",
    "    # Father's name check\n",
    "    father_list = list(father_name.split(' '))\n",
    "    count_father = 0\n",
    "    for item in father_list:\n",
    "        if item.upper() in ocr_text_back.upper():\n",
    "            count_father = count_father +1\n",
    "\n",
    "    percent_correct_father = count_father/len(father_list)\n",
    "    simlarity_score[\"Father_name\"] = percent_correct_father\n",
    "    if percent_correct_father==1:\n",
    "\n",
    "        print(\"Father Name is correct.....\")\n",
    "        print(\"----------------------------\")\n",
    "        count_back = count_back+1\n",
    "        data_check[\"Father_name\"] = \"Validated\"\n",
    "        final_data[\"Father_name\"] = father_name\n",
    "\n",
    "    else:\n",
    "        print(\"Father Name is incorrect.....\")\n",
    "        print(\"----------------------------\")\n",
    "        data_check[\"Father_name\"] = \"Not Validated\"\n",
    "        final_data[\"Father_name\"] = \"NA\"\n",
    "    # Pin code Check\n",
    "    if str(pincode) in ocr_text_back:\n",
    "        print(\"Pincode is correct.....\")\n",
    "        print(\"----------------------------\")\n",
    "        count_back = count_back +1\n",
    "        data_check[\"pincode\"] = \"Validated\"\n",
    "        final_data[\"pincode\"] = pincode\n",
    "        simlarity_score[\"pincode\"] = 1\n",
    "    else:\n",
    "        print(\"Pincode is incorrect.....\")\n",
    "        print(\"----------------------------\")\n",
    "        data_check[\"pincode\"] = \"Not Validated\"\n",
    "        final_data[\"pincode\"] = \"NA\"\n",
    "        simlarity_score[\"pincode\"] = 0\n",
    "\n",
    "    #Address Check\n",
    "    address_list = list(address.split(' '))\n",
    "    count_address = 0\n",
    "    for item in address_list:\n",
    "        if item.upper() in ocr_text_back.upper():\n",
    "            count_address = count_address +1\n",
    "\n",
    "    percent_correct_address = count_address/len(address_list)\n",
    "    simlarity_score[\"address\"] = percent_correct_address\n",
    "    if percent_correct_address >= 0.5:\n",
    "        print(\"Address is correct.....\")\n",
    "        print(\"----------------------------\")\n",
    "        count_back = count_back+1\n",
    "        data_check[\"address\"] = \"Validated\"\n",
    "        final_data[\"address\"] = address\n",
    "    else:\n",
    "        print(\"Address is incorrect.....\")\n",
    "        print(\"----------------------------\")\n",
    "        data_check[\"address\"] = \"Not Validated\"\n",
    "        final_data[\"address\"] = \"NA\"\n",
    "\n",
    "    return count_front,count_back\n",
    "\n",
    "#------------------------- Extracted Text Validation Ends Here -----------------------------\n",
    "#------------------------- Card Information Validation Counter Starts Here -----------------\n",
    "\n",
    "\n",
    "def status_of_card_validation(count_front,count_back):\n",
    "    #FRONT\n",
    "    if count_front==4:\n",
    "        colored_text = colored(0,255, 0, 'FRONT APPROVED ')\n",
    "        print(colored_text)\n",
    "\n",
    "    else:\n",
    "        colored_text = colored(255,0,0, 'FRONT NOT APPROVED')\n",
    "        print(colored_text)\n",
    "    print(\"---------------------\")  \n",
    "    #BACK\n",
    "    if count_back==3:\n",
    "        colored_text = colored(0,255, 0, 'BACK APPROVED')\n",
    "        print(colored_text)\n",
    "        print(\"---------------------\")\n",
    "    else:\n",
    "        colored_text = colored(255,0,0, 'BACK NOT APPROVED')\n",
    "        print(colored_text)\n",
    "        print(\"---------------------\")\n",
    "    print(\"---------------------\")\n",
    "    #COMBINE\n",
    "    global count\n",
    "    count = count_front + count_back + count\n",
    "    \n",
    "    if count==11:\n",
    "        colored_text = colored(0,255, 0, 'Provided details are matching with Adhar')\n",
    "        print(colored_text)\n",
    "        print(colored(0,255, 0, 'OVERALL APPROVED'))\n",
    "        print(\"---------------------\")\n",
    "    else:\n",
    "        colored_text = colored(255,0,0, 'Provided details are not matching with Adhar')\n",
    "        print(colored_text) \n",
    "        print(colored(255,0, 0, 'OVERALL NOT APPROVED'))\n",
    "        print(\"---------------------\")\n",
    "    print(\"---------------------\")\n",
    "    \n",
    "def colored(r, g, b, text):\n",
    "    return \"\\033[38;2;{};{};{}m{} \\033[38;2;255;255;255m\".format(r, g, b, text)\n",
    "\n",
    "#------------------------- Card Information Validation Counter Ends Here -----------------  \n",
    "\n",
    "#--------------------------UIDAI Check Starts Here ----------------------------------\n",
    "def uidai_check(adhar_number):  \n",
    "\n",
    "    conn = pyodbc.connect(\"Driver={SQL Server};\"\n",
    "                      \"Server=LTI-MEAN-63\\SQLEXPRESS;\"\n",
    "                      \"Database=SOLVATHON;\"\n",
    "                      \"Trusted_Connection=Yes;\")\n",
    "\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "\n",
    "    cursor.execute(\"SELECT * FROM UIDAI_DATABASE WHERE [Adhaar_Number]='%s'\" % adhar_number)\n",
    "    global uidai_adhaar \n",
    "    global uidai_name \n",
    "    global uidai_gender \n",
    "    global uidai_father_name\n",
    "    global uidai_contact \n",
    "    global uidai_dob \n",
    "    global uidai_address \n",
    "    global uidai_pincode \n",
    "\n",
    "    for row in cursor:\n",
    "        uidai_adhaar = row[0]\n",
    "        uidai_name = row[1]\n",
    "        uidai_gender = row[2]\n",
    "        uidai_father_name = row[3]\n",
    "        uidai_contact = row[4]\n",
    "        uidai_dob = row[5]\n",
    "        uidai_address = row[6]\n",
    "        uidai_pincode = row[7]\n",
    "\n",
    "\n",
    "    global count\n",
    "    global uidai_count\n",
    "    \n",
    "    uidai_count =0\n",
    "    \n",
    "    \n",
    "    #adhar number\n",
    "    if final_data['UID'][0] == uidai_adhaar:\n",
    "        uidai_count =uidai_count+1\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI ADdhaar NOT Matched------------------------------\")))\n",
    "    #Name\n",
    "    if final_data['name'][0].upper() == uidai_name.upper():\n",
    "        uidai_count =uidai_count+1\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI Name NOT Matched------------------------------\")))\n",
    "    #gender\n",
    "    if final_data['Gender'][0].upper() == uidai_gender.upper():\n",
    "        uidai_count =uidai_count+1\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI Gender NOT Matched------------------------------\")))\n",
    "    #Father\n",
    "    if final_data['Father_name'][0].upper() == uidai_father_name.upper():\n",
    "        uidai_count =uidai_count+1\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI Father Name NOT Matched------------------------------\")))\n",
    "    #DOB\n",
    "    if final_data['date_of_birth'][0] == uidai_dob:\n",
    "        uidai_count =uidai_count+1\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI DOB NOT Matched------------------------------\")))\n",
    "    #Pincode\n",
    "    if str(final_data['pincode'][0]) == str(uidai_pincode):\n",
    "        uidai_count =uidai_count+1\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI Pincode NOT Matched------------------------------\")))\n",
    "\n",
    "    #Address Check\n",
    "    address_list_1 = list(uidai_address.split(' '))\n",
    "    count_address_1 =0 \n",
    "    for item in address_list_1:\n",
    "        if item.upper() in final_data['address'][0].upper():\n",
    "            count_address_1 = count_address_1 +1\n",
    "\n",
    "    percent_correct_address_1 = count_address_1/len(address_list_1)\n",
    "\n",
    "    if percent_correct_address_1 >= 0.5:\n",
    "        uidai_count =uidai_count+1\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI Address NOT Matched------------------------------\")))\n",
    "    \n",
    "    if uidai_count == 7:\n",
    "        count = count +1\n",
    "        print(print(colored(0,255, 0, \"UIDAI Matched------------------------------\")))\n",
    "    else:\n",
    "        print(print(colored(255,0, 0, \"UIDAI NOT Matched------------------------------\")))\n",
    "        \n",
    "    \n",
    "\n",
    "#--------------------------UIDAI Check END Here ----------------------------------        \n",
    "    \n",
    "#------------------------- Driver Function Starts Here -----------------------------------\n",
    "\n",
    "def Executor(name, date_of_birth, gender, uid, father_name, address, pincode, front_image, back_image, photo_graph, path_to_emblem_template, path_to_goi_template, appno):\n",
    "    initial()\n",
    "    global count\n",
    "    global fail_counter\n",
    "    \n",
    "    #ADD SPACES IN UID\n",
    "    first_part = uid[0:4]+' '\n",
    "    second_part = uid[4:8]+' '\n",
    "    third_part = uid[8:12]\n",
    "    uid = first_part+second_part+third_part\n",
    "    \n",
    "    # Input to Face Similarity\n",
    "\n",
    "    face_similarity_executor(front_image, photo_graph)\n",
    "\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    emblem_validation_executor(front_image, path_to_emblem_template)\n",
    "\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    goi_detection(front_image, path_to_emblem_template, path_to_goi_template)\n",
    "\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    verhoff_algo(uid)\n",
    "\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    ocr_text_front=adhar_front_text_extraction(front_image)\n",
    "    ocr_text_back = adhar_back_text_extraction(back_image)\n",
    "    validated=card_validation(ocr_text_front,ocr_text_back,name,date_of_birth,gender,uid,father_name,pincode,address)\n",
    "\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    count_front,count_back = validated\n",
    "    status_of_card_validation(count_front,count_back)\n",
    "\n",
    "    global simlarity_score\n",
    "    global final_data\n",
    "\n",
    "    final_data = pd.DataFrame.from_dict(final_data , orient='index').T.astype(\"string\")\n",
    "    simlarity_score = pd.DataFrame.from_dict(simlarity_score , orient='index').T.astype('string')\n",
    "    final_data[\"Face_Similarity_Score\"] = simlarity_score[\"Face_Similarity_Score\"]\n",
    "    final_data[\"Emblem_Validation_Score\"] = simlarity_score[\"Emblem_Validation_Score\"]\n",
    "\n",
    "    uidai_check(uid)\n",
    "\n",
    "    if count==12:\n",
    "        final_data[\"Authentication_Status\"] = \"Passed\"\n",
    "        final_data[\"Fail_Counter\"] = fail_counter\n",
    "        update_db(appno)\n",
    "        return \"KYC Successful\"\n",
    "    else:\n",
    "        final_data[\"Authentication_Status\"] = \"Failed\"\n",
    "        fail_counter = fail_counter + 1\n",
    "        final_data[\"Fail_Counter\"] = fail_counter\n",
    "        update_db(appno)\n",
    "        return \"KYC Unsuccessful\"\n",
    "\n",
    "\n",
    "def update_db(appno):\n",
    "    \n",
    "    # global simlarity_score\n",
    "    # global final_data\n",
    "    \n",
    "    # final_data = pd.DataFrame.from_dict(final_data , orient='index').T.astype(\"string\")\n",
    "    # simlarity_score = pd.DataFrame.from_dict(simlarity_score , orient='index').T.astype('string')\n",
    "    # final_data[\"Face_Similarity_Score\"] = simlarity_score[\"Face_Similarity_Score\"]\n",
    "    # final_data[\"Emblem_Validation_Score\"] = simlarity_score[\"Emblem_Validation_Score\"]\n",
    "\n",
    "    conn = pyodbc.connect(\"Driver={SQL Server};\"\n",
    "                      \"Server=LTI-MEAN-63\\SQLEXPRESS;\"\n",
    "                      \"Database=SOLVATHON;\"\n",
    "                      \"Trusted_Connection=Yes;\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    for row in final_data.itertuples():\n",
    "        cursor.execute('''\n",
    "                UPDATE CustomerDetailsSolvathon\n",
    "                SET Authentication_Status = ?,Failure_Count = ?,Face_Detection_Accuracy = ?,Emblem_Detection_Accuracy = ?\n",
    "                WHERE Application_Number = ?\n",
    "                ''',\n",
    "                row.Authentication_Status,\n",
    "                row.Fail_Counter,\n",
    "                row.Face_Similarity_Score,\n",
    "                row.Emblem_Validation_Score,\n",
    "                appno\n",
    "                )\n",
    "        conn.commit()\n",
    "\n",
    "        return \"DB Updated\"\n",
    "\n",
    "Executor('Shishir Gupta', '01/02/1999', 'MALE', '261363713327', 'Sanjay Gupta', 'BMMIG - 29 INDRAPURAM AGRA', int(282001), 'front.jpg', 'back.jpg', 'pic.jpg', 'crop_emblem_2.jpg', 'crop_goi.jpg', 'SHIS3327')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
